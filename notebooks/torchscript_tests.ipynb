{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorCache(nn.Module):\n",
    "    def __init__(self, tensor):\n",
    "        super(TensorCache, self).__init__()\n",
    "        # cache = nn.Parameter(tensor)\n",
    "        # self.register_parameter('cache', cache)\n",
    "        self.register_buffer('cache', tensor)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # assert x.size() == self.cache[:,:,0:1].size()\n",
    "        cache_update = torch.cat((self.cache[:,:,1:], x.detach()), dim=2)\n",
    "        self.cache[:,:,:] = cache_update\n",
    "        return self.cache\n",
    "    \n",
    "#     def forward(self):\n",
    "#         return self.cache\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def zero_cache(self):\n",
    "        self.cache[:,:,:] = torch.ones(self.cache.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def update_cache(cache, x):\n",
    "#     return torch.cat((cache[:,:,1:], x.detach()), dim=2)\n",
    "#     cache_update = torch.cat((cache[:,:,1:], x.detach()), dim=2)\n",
    "#     cache[:,:,:] = cache_update\n",
    "    cache[:,:,-1] = x[:,:,0].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "outputs_[i]->uses().empty() INTERNAL ASSERT FAILED at \"/pytorch/torch/csrc/jit/ir/ir.cpp\":1176, please report a bug to PyTorch. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7093b827f0e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtc_script\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtc_trace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0m_module_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         )\n\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                 \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m             )\n\u001b[1;32m    942\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: outputs_[i]->uses().empty() INTERNAL ASSERT FAILED at \"/pytorch/torch/csrc/jit/ir/ir.cpp\":1176, please report a bug to PyTorch. "
     ]
    }
   ],
   "source": [
    "tc = TensorCache(torch.zeros(1,1,10))\n",
    "tc_script = torch.jit.script(tc)\n",
    "tc_trace = torch.jit.trace(tc, torch.tensor([[[0]]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 1., 2.]]])\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 2., 3.]]])\n",
      "tensor([[[0., 0., 0., 0., 0., 0., 1., 2., 3., 4.]]])\n",
      "\n",
      "Convert using script:\n",
      "tensor([[[0., 0., 0., 0., 0., 1., 2., 3., 4., 1.]]])\n",
      "tensor([[[0., 0., 0., 0., 1., 2., 3., 4., 1., 2.]]])\n",
      "tensor([[[0., 0., 0., 1., 2., 3., 4., 1., 2., 3.]]])\n",
      "tensor([[[0., 0., 1., 2., 3., 4., 1., 2., 3., 4.]]])\n",
      "\n",
      "Convert using trace:\n",
      "tensor([[[0., 1., 2., 3., 4., 1., 2., 3., 4., 1.]]])\n",
      "tensor([[[1., 2., 3., 4., 1., 2., 3., 4., 1., 2.]]])\n",
      "tensor([[[2., 3., 4., 1., 2., 3., 4., 1., 2., 3.]]])\n",
      "tensor([[[3., 4., 1., 2., 3., 4., 1., 2., 3., 4.]]])\n"
     ]
    }
   ],
   "source": [
    "print('Original:')\n",
    "for inp in [1,2,3,4]:\n",
    "    print(tc(torch.tensor([[[inp]]])))\n",
    "\n",
    "print()\n",
    "print('Convert using script:')\n",
    "for inp in [1,2,3,4]:\n",
    "    print(tc_script(torch.tensor([[[inp]]])))\n",
    "    \n",
    "print('')\n",
    "print('Convert using trace:')\n",
    "for inp in [1,2,3,4]:\n",
    "    print(tc_trace(torch.tensor([[[inp]]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalInferenceBlock(nn.Module):\n",
    "# class TemporalInferenceBlock(torch.jit.ScriptModule):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, batch_size=1):\n",
    "        super(TemporalInferenceBlock, self).__init__()\n",
    "        self.in_ch, self.k, self.d = n_inputs, kernel_size, dilation\n",
    "\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=0, dilation=dilation))\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                                           stride=stride, padding=0, dilation=dilation))\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.cache1 = torch.jit.script(TensorCache(torch.zeros(\n",
    "            batch_size, \n",
    "            self.conv1.in_channels, \n",
    "            (self.conv1.kernel_size[0]-1)*self.conv1.dilation[0] + 1\n",
    "            )))\n",
    "        \n",
    "        self.cache2 = torch.jit.script(TensorCache(torch.zeros(\n",
    "            batch_size, \n",
    "            self.conv2.in_channels, \n",
    "            (self.conv2.kernel_size[0]-1)*self.conv2.dilation[0] + 1\n",
    "            )))\n",
    "\n",
    "#         self.cache1 = torch.zeros(\n",
    "#             batch_size, \n",
    "#             self.conv1.in_channels, \n",
    "#             (self.conv1.kernel_size[0]-1)*self.conv1.dilation[0] + 1\n",
    "#             )\n",
    "            \n",
    "#         self.cache2 = torch.zeros(\n",
    "#             batch_size, \n",
    "#             self.conv2.in_channels, \n",
    "#             (self.conv2.kernel_size[0]-1)*self.conv2.dilation[0] + 1\n",
    "#             )\n",
    "        \n",
    "        self.stage1 = nn.Sequential(self.conv1, self.relu1)\n",
    "        self.stage2 = nn.Sequential(self.conv2, self.relu2)\n",
    "\n",
    "\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else nn.Identity()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if isinstance(self.downsample, nn.modules.conv.Conv1d):\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def reset_cache(self):\n",
    "        self.cache1.zero_cache()\n",
    "        self.cache2.zero_cache()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x is of shape (B, CH, 1)\n",
    "        '''\n",
    "        # out = self.stage1(self.cache1(x)[:x.size()[0], :, :])\n",
    "        # out = self.stage2(self.cache2(out)[:x.size()[0], :, :])\n",
    "        # out1 = self.stage1(self.cache1(x))\n",
    "        # out2 = self.stage2(self.cache2(out1))\n",
    "        \n",
    "        out1 = self.relu1(self.conv1(self.cache1(x)))\n",
    "        out2 = self.relu2(self.conv2(self.cache2(out1)))\n",
    "        # self.cache1.zero_cache()\n",
    "        # out1 = self.cache1()\n",
    "        # self.cache2.zero_cache()\n",
    "        # out2 = self.cache2()\n",
    "\n",
    "        res = self.downsample(x)\n",
    "        out = self.relu(out2 + res)\n",
    "        # print(f'\\t res shape: {res.size()}')\n",
    "        #         print(f'x: {x} \\n c1: {self.cache1.cache} \\n out1: {out1} \\n c2: {self.cache2.cache} \\n out2: {out2} \\n \\n')\n",
    "\n",
    "        return x, self.cache1.cache, out1, self.cache2.cache, out2, res, out\n",
    "    \n",
    "#     @torch.jit.script_method\n",
    "#     def forward(self, x):\n",
    "#         '''\n",
    "#         x is of shape (B, CH, 1)\n",
    "#         '''\n",
    "#         # out = self.stage1(self.cache1(x)[:x.size()[0], :, :])\n",
    "#         # out = self.stage2(self.cache2(out)[:x.size()[0], :, :])\n",
    "#         update_cache(self.cache1, x)\n",
    "#         out1 = self.stage1(self.cache1)\n",
    "#         update_cache(self.cache2, out1)\n",
    "#         out2 = self.stage2(self.cache2)\n",
    "\n",
    "#         res = self.downsample(x)\n",
    "#         out = self.relu(out2 + res)\n",
    "#         # print(f'\\t res shape: {res.size()}')\n",
    "#         #         print(f'x: {x} \\n c1: {self.cache1.cache} \\n out1: {out1} \\n c2: {self.cache2.cache} \\n out2: {out2} \\n \\n')\n",
    "\n",
    "#         return x, self.cache1, out1, self.cache2, out2, res, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "tblock = TemporalInferenceBlock(1,1,7,1,1,1)\n",
    "tblock.eval()\n",
    "tblock.cuda()\n",
    "\n",
    "tblock_script = torch.jit.script(tblock)\n",
    "tblock_trace = torch.jit.trace(tblock, torch.tensor([[[0]]]).cuda())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[1]]], device='cuda:0') \n",
      " c1: tensor([[[0., 0., 0., 0., 0., 0., 1.]]], device='cuda:0') \n",
      " out1: tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0') \n",
      " out2: tensor([[[0.1345]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[1]]], device='cuda:0') \n",
      " out: tensor([[[1.1345]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n",
      "x: tensor([[[2]]], device='cuda:0') \n",
      " c1: tensor([[[0., 0., 0., 0., 0., 1., 2.]]], device='cuda:0') \n",
      " out1: tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0') \n",
      " out2: tensor([[[0.1345]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[2]]], device='cuda:0') \n",
      " out: tensor([[[2.1345]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n",
      "x: tensor([[[3]]], device='cuda:0') \n",
      " c1: tensor([[[0., 0., 0., 0., 1., 2., 3.]]], device='cuda:0') \n",
      " out1: tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0') \n",
      " out2: tensor([[[0.1345]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[3]]], device='cuda:0') \n",
      " out: tensor([[[3.1345]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n",
      "x: tensor([[[4]]], device='cuda:0') \n",
      " c1: tensor([[[0., 0., 0., 1., 2., 3., 4.]]], device='cuda:0') \n",
      " out1: tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0') \n",
      " out2: tensor([[[0.1345]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[4]]], device='cuda:0') \n",
      " out: tensor([[[4.1345]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp in [1,2,3,4]:\n",
    "    x, c1, out1, c2, out2, res, out = tblock(torch.tensor([[[inp]]]).cuda())\n",
    "    print(f'x: {x} \\n c1: {c1} \\n out1: {out1} \\n c2: {c2} \\n out2: {out2}, res: {res} \\n out: {out} \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<ipython-input-326-ecfa1ebd866b>\", line 65, in forward\n        # out = self.stage1(self.cache1(x)[:x.size()[0], :, :])\n        # out = self.stage2(self.cache2(out)[:x.size()[0], :, :])\n        out1 = self.stage1(self.cache1(x))\n               ~~~~~~~~~~~ <--- HERE\n        out2 = self.stage2(self.cache2(out1))\n        # self.cache1.zero_cache()\n  File \"/home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 258, in forward\n                            self.weight, self.bias, self.stride,\n                            _single(0), self.dilation, self.groups)\n        return F.conv1d(input, self.weight, self.bias, self.stride,\n               ~~~~~~~~ <--- HERE\n                        self.padding, self.dilation, self.groups)\nRuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-390-a275ac3c1135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtblock_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'x: {x} \\n c1: {c1} \\n out1: {out1} \\n c2: {c2} \\n out2: {out2}, res: {res} \\n out: {out} \\n \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<ipython-input-326-ecfa1ebd866b>\", line 65, in forward\n        # out = self.stage1(self.cache1(x)[:x.size()[0], :, :])\n        # out = self.stage2(self.cache2(out)[:x.size()[0], :, :])\n        out1 = self.stage1(self.cache1(x))\n               ~~~~~~~~~~~ <--- HERE\n        out2 = self.stage2(self.cache2(out1))\n        # self.cache1.zero_cache()\n  File \"/home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 117, in forward\n    def forward(self, input):\n        for module in self:\n            input = module(input)\n                    ~~~~~~ <--- HERE\n        return input\n  File \"/home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 258, in forward\n                            self.weight, self.bias, self.stride,\n                            _single(0), self.dilation, self.groups)\n        return F.conv1d(input, self.weight, self.bias, self.stride,\n               ~~~~~~~~ <--- HERE\n                        self.padding, self.dilation, self.groups)\nRuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n"
     ]
    }
   ],
   "source": [
    "for inp in [1,2,3,4]:\n",
    "    x, c1, out1, c2, out2, res, out = tblock_script(torch.tensor([[[inp]]]).cuda())\n",
    "    print(f'x: {x} \\n c1: {c1} \\n out1: {out1} \\n c2: {c2} \\n out2: {out2}, res: {res} \\n out: {out} \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[1]]], device='cuda:0') \n",
      " c1: tensor([[[0., 1., 2., 3., 4., 1., 1.]]], device='cuda:0') \n",
      " out1: tensor([[[0.2580]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2580]]],\n",
      "       device='cuda:0') \n",
      " out2: tensor([[[0.0769]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[1]]], device='cuda:0') \n",
      " out: tensor([[[1.0769]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n",
      "x: tensor([[[2]]], device='cuda:0') \n",
      " c1: tensor([[[1., 2., 3., 4., 1., 1., 2.]]], device='cuda:0') \n",
      " out1: tensor([[[0.5571]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2580, 0.5571]]],\n",
      "       device='cuda:0') \n",
      " out2: tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[2]]], device='cuda:0') \n",
      " out: tensor([[[2.]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n",
      "x: tensor([[[3]]], device='cuda:0') \n",
      " c1: tensor([[[2., 3., 4., 1., 1., 2., 3.]]], device='cuda:0') \n",
      " out1: tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.2580, 0.5571, 0.0000]]],\n",
      "       device='cuda:0') \n",
      " out2: tensor([[[0.0877]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[3]]], device='cuda:0') \n",
      " out: tensor([[[3.0877]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n",
      "x: tensor([[[4]]], device='cuda:0') \n",
      " c1: tensor([[[3., 4., 1., 1., 2., 3., 4.]]], device='cuda:0') \n",
      " out1: tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " c2: tensor([[[0.0000, 0.0000, 0.0000, 0.2580, 0.5571, 0.0000, 0.0000]]],\n",
      "       device='cuda:0') \n",
      " out2: tensor([[[0.0617]]], device='cuda:0', grad_fn=<ReluBackward0>), res: tensor([[[4]]], device='cuda:0') \n",
      " out: tensor([[[4.0617]]], device='cuda:0', grad_fn=<ReluBackward0>) \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inp in [1,2,3,4]:\n",
    "    x, c1, out1, c2, out2, res, out = tblock_trace(torch.tensor([[[inp]]]).cuda())\n",
    "    print(f'x: {x} \\n c1: {c1} \\n out1: {out1} \\n c2: {c2} \\n out2: {out2}, res: {res} \\n out: {out} \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.]]], device='cuda:0'),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'),\n",
       " tensor([[[0.]]], device='cuda:0', grad_fn=<ReluBackward0>),\n",
       " tensor([[[0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0'),\n",
       " tensor([[[0.1974]]], device='cuda:0', grad_fn=<ReluBackward0>),\n",
       " tensor([[[0.]]], device='cuda:0'),\n",
       " tensor([[[0.1974]]], device='cuda:0', grad_fn=<ReluBackward0>))"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out = tblock_trace(torch.tensor([[[0.0]]]).cuda())\n",
    "test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%output : Float(1:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %1 : Float(1:1, requires_grad=1, device=cuda:0),\n",
      "      %4 : Float(1:1, requires_grad=1, device=cuda:0),\n",
      "      %7 : Float(1:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %8 : Float(1:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %169 : Float(1:7, 1:7, 6:1, requires_grad=0, device=cuda:0),\n",
      "      %170 : Long(3:1, requires_grad=0, device=cpu),\n",
      "      %173 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %176 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %179 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %181 : Long(0:1, requires_grad=0, device=cpu),\n",
      "      %184 : Float(1:7, 1:7, 7:1, requires_grad=1, device=cuda:0),\n",
      "      %185 : Float(1:7, 1:7, 6:1, requires_grad=0, device=cuda:0),\n",
      "      %186 : Long(3:1, requires_grad=0, device=cpu),\n",
      "      %189 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %192 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %195 : Long(1:1, requires_grad=0, device=cpu),\n",
      "      %197 : Long(0:1, requires_grad=0, device=cpu),\n",
      "      %200 : Float(1:7, 1:7, 7:1, requires_grad=1, device=cuda:0)):\n",
      "  %14 : Tensor = onnx::Concat[axis=2](%169, %output) # <ipython-input-325-b9470826e8b6>:10:23\n",
      "  %16 : Tensor = onnx::Expand(%14, %170) # <ipython-input-325-b9470826e8b6>:11:8\n",
      "  %21 : Tensor = onnx::Constant[value={0}]()\n",
      "  %22 : Tensor = onnx::Constant[value={1}]()\n",
      "  %23 : Tensor = onnx::Range(%21, %173, %22)\n",
      "  %28 : Tensor = onnx::Constant[value={0}]()\n",
      "  %29 : Tensor = onnx::Constant[value={1}]()\n",
      "  %30 : Tensor = onnx::Range(%28, %176, %29)\n",
      "  %35 : Tensor = onnx::Constant[value={0}]()\n",
      "  %36 : Tensor = onnx::Constant[value={1}]()\n",
      "  %37 : Tensor = onnx::Range(%35, %179, %36)\n",
      "  %38 : Tensor = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()\n",
      "  %39 : Tensor = onnx::Reshape(%23, %38)\n",
      "  %40 : Tensor = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "  %41 : Tensor = onnx::Reshape(%30, %40)\n",
      "  %42 : Tensor = onnx::Constant[value={-1}]()\n",
      "  %43 : Tensor = onnx::Reshape(%37, %42)\n",
      "  %44 : Tensor = onnx::Add(%39, %41)\n",
      "  %45 : Tensor = onnx::Add(%44, %43)\n",
      "  %46 : Tensor = onnx::Shape(%45)\n",
      "  %47 : Tensor = onnx::Shape(%46)\n",
      "  %48 : Tensor = onnx::ConstantOfShape[value={1}](%47)\n",
      "  %49 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %50 : LongTensor = onnx::Mul(%48, %49)\n",
      "  %51 : Tensor = onnx::Equal(%46, %50)\n",
      "  %52 : Tensor = onnx::Cast[to=9](%51)\n",
      "  %53 : Tensor = onnx::Where(%52, %48, %46)\n",
      "  %54 : Tensor = onnx::Expand(%39, %53)\n",
      "  %55 : Tensor = onnx::Unsqueeze[axes=[-1]](%54)\n",
      "  %56 : Tensor = onnx::Shape(%46)\n",
      "  %57 : Tensor = onnx::ConstantOfShape[value={1}](%56)\n",
      "  %58 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %59 : LongTensor = onnx::Mul(%57, %58)\n",
      "  %60 : Tensor = onnx::Equal(%46, %59)\n",
      "  %61 : Tensor = onnx::Cast[to=9](%60)\n",
      "  %62 : Tensor = onnx::Where(%61, %57, %46)\n",
      "  %63 : Tensor = onnx::Expand(%41, %62)\n",
      "  %64 : Tensor = onnx::Unsqueeze[axes=[-1]](%63)\n",
      "  %65 : Tensor = onnx::Shape(%46)\n",
      "  %66 : Tensor = onnx::ConstantOfShape[value={1}](%65)\n",
      "  %67 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %68 : LongTensor = onnx::Mul(%66, %67)\n",
      "  %69 : Tensor = onnx::Equal(%46, %68)\n",
      "  %70 : Tensor = onnx::Cast[to=9](%69)\n",
      "  %71 : Tensor = onnx::Where(%70, %66, %46)\n",
      "  %72 : Tensor = onnx::Expand(%43, %71)\n",
      "  %73 : Tensor = onnx::Unsqueeze[axes=[-1]](%72)\n",
      "  %74 : Tensor = onnx::Concat[axis=-1](%55, %64, %73)\n",
      "  %80 : Tensor = onnx::Concat[axis=0](%46, %181)\n",
      "  %81 : Tensor = onnx::Reshape(%16, %80)\n",
      "  %82 : Float(1:7, 1:7, 7:1, requires_grad=0, device=cuda:0) = onnx::ScatterND(%7, %74, %81)\n",
      "  %86 : Float(1:1, 1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[0, 0], strides=[1]](%82, %184, %1), scope: __module.stage1.0 # /home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py:259:0\n",
      "  %87 : Float(1:1, 1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::Relu(%86) # <ipython-input-325-b9470826e8b6>:10:54\n",
      "  %93 : Tensor = onnx::Concat[axis=2](%185, %87) # <ipython-input-325-b9470826e8b6>:10:23\n",
      "  %95 : Tensor = onnx::Expand(%93, %186) # <ipython-input-325-b9470826e8b6>:11:8\n",
      "  %100 : Tensor = onnx::Constant[value={0}]()\n",
      "  %101 : Tensor = onnx::Constant[value={1}]()\n",
      "  %102 : Tensor = onnx::Range(%100, %189, %101)\n",
      "  %107 : Tensor = onnx::Constant[value={0}]()\n",
      "  %108 : Tensor = onnx::Constant[value={1}]()\n",
      "  %109 : Tensor = onnx::Range(%107, %192, %108)\n",
      "  %114 : Tensor = onnx::Constant[value={0}]()\n",
      "  %115 : Tensor = onnx::Constant[value={1}]()\n",
      "  %116 : Tensor = onnx::Range(%114, %195, %115)\n",
      "  %117 : Tensor = onnx::Constant[value=-1  1  1 [ CPULongType{3} ]]()\n",
      "  %118 : Tensor = onnx::Reshape(%102, %117)\n",
      "  %119 : Tensor = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "  %120 : Tensor = onnx::Reshape(%109, %119)\n",
      "  %121 : Tensor = onnx::Constant[value={-1}]()\n",
      "  %122 : Tensor = onnx::Reshape(%116, %121)\n",
      "  %123 : Tensor = onnx::Add(%118, %120)\n",
      "  %124 : Tensor = onnx::Add(%123, %122)\n",
      "  %125 : Tensor = onnx::Shape(%124)\n",
      "  %126 : Tensor = onnx::Shape(%125)\n",
      "  %127 : Tensor = onnx::ConstantOfShape[value={1}](%126)\n",
      "  %128 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %129 : LongTensor = onnx::Mul(%127, %128)\n",
      "  %130 : Tensor = onnx::Equal(%125, %129)\n",
      "  %131 : Tensor = onnx::Cast[to=9](%130)\n",
      "  %132 : Tensor = onnx::Where(%131, %127, %125)\n",
      "  %133 : Tensor = onnx::Expand(%118, %132)\n",
      "  %134 : Tensor = onnx::Unsqueeze[axes=[-1]](%133)\n",
      "  %135 : Tensor = onnx::Shape(%125)\n",
      "  %136 : Tensor = onnx::ConstantOfShape[value={1}](%135)\n",
      "  %137 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %138 : LongTensor = onnx::Mul(%136, %137)\n",
      "  %139 : Tensor = onnx::Equal(%125, %138)\n",
      "  %140 : Tensor = onnx::Cast[to=9](%139)\n",
      "  %141 : Tensor = onnx::Where(%140, %136, %125)\n",
      "  %142 : Tensor = onnx::Expand(%120, %141)\n",
      "  %143 : Tensor = onnx::Unsqueeze[axes=[-1]](%142)\n",
      "  %144 : Tensor = onnx::Shape(%125)\n",
      "  %145 : Tensor = onnx::ConstantOfShape[value={1}](%144)\n",
      "  %146 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %147 : LongTensor = onnx::Mul(%145, %146)\n",
      "  %148 : Tensor = onnx::Equal(%125, %147)\n",
      "  %149 : Tensor = onnx::Cast[to=9](%148)\n",
      "  %150 : Tensor = onnx::Where(%149, %145, %125)\n",
      "  %151 : Tensor = onnx::Expand(%122, %150)\n",
      "  %152 : Tensor = onnx::Unsqueeze[axes=[-1]](%151)\n",
      "  %153 : Tensor = onnx::Concat[axis=-1](%134, %143, %152)\n",
      "  %159 : Tensor = onnx::Concat[axis=0](%125, %197)\n",
      "  %160 : Tensor = onnx::Reshape(%95, %159)\n",
      "  %161 : Float(1:7, 1:7, 7:1, requires_grad=0, device=cuda:0) = onnx::ScatterND(%8, %153, %160)\n",
      "  %165 : Float(1:1, 1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1], group=1, kernel_shape=[7], pads=[0, 0], strides=[1]](%161, %200, %4), scope: __module.stage2.0 # /home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/modules/conv.py:259:0\n",
      "  %166 : Float(1:1, 1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::Relu(%165), scope: __module.stage2.1 # /home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/functional.py:1136:0\n",
      "  %167 : Float(1:1, 1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::Add(%166, %output) # <ipython-input-416-a7232f9440d7>:76:0\n",
      "  %168 : Float(1:1, 1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::Relu(%167), scope: __module.relu # /home/s1bhavsa/.local/lib/python3.7/site-packages/torch/nn/functional.py:1136:0\n",
      "  return (%output, %82, %87, %161, %166, %output, %168)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    tblock_trace,\n",
    "    torch.tensor([[[0.0]]]).cuda(),\n",
    "    f'tblock_test.onnx',\n",
    "    export_params=True,\n",
    "    do_constant_folding=True,\n",
    "    keep_initializers_as_inputs=True,\n",
    "    opset_version=12,\n",
    "    input_names = ['input'],\n",
    "    output_names = ['output'],\n",
    "#     dynamic_axes={\n",
    "#                  'input' : {0 : 'batch_size'}, \n",
    "#                  'output' : {0 : 'batch_size'}\n",
    "#                  },\n",
    "    example_outputs=test_out,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import helper, shape_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load('tblock_test.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_model = shape_inference.infer_shapes(onnx_model)\n",
    "onnx.checker.check_model(inferred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "ename": "Fail",
     "evalue": "[ONNXRuntimeError] : 1 : FAIL : Exception during loading: /onnxruntime_src/onnxruntime/core/graph/function.cc:391 onnxruntime::FunctionImpl::FunctionImpl(const onnxruntime::Graph&, const NodeIndex&, const onnx::FunctionProto&, const onnxruntime::logging::Logger&) status.IsOK() was false. Resolve subgraph failed:Node (0x55678227b6c0_2) Op (Loop) [TypeInferenceError] Graph attribute inferencing failed: Node:0x55678227b6c0_2 Output:cond [ShapeInferenceError] Mismatch between number of source and target dimensions. Source=1 Target=0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFail\u001b[0m                                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-423-43fcc864267d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0monnx_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tblock_test.onnx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mort_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, providers)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to load from type '{0}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFail\u001b[0m: [ONNXRuntimeError] : 1 : FAIL : Exception during loading: /onnxruntime_src/onnxruntime/core/graph/function.cc:391 onnxruntime::FunctionImpl::FunctionImpl(const onnxruntime::Graph&, const NodeIndex&, const onnx::FunctionProto&, const onnxruntime::logging::Logger&) status.IsOK() was false. Resolve subgraph failed:Node (0x55678227b6c0_2) Op (Loop) [TypeInferenceError] Graph attribute inferencing failed: Node:0x55678227b6c0_2 Output:cond [ShapeInferenceError] Mismatch between number of source and target dimensions. Source=1 Target=0\n"
     ]
    }
   ],
   "source": [
    "onnx_path = 'tblock_test.onnx'\n",
    "ort_session = onnxruntime.InferenceSession(str(onnx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ByteSize',\n",
       " 'Clear',\n",
       " 'ClearExtension',\n",
       " 'ClearField',\n",
       " 'CopyFrom',\n",
       " 'DESCRIPTOR',\n",
       " 'DiscardUnknownFields',\n",
       " 'Extensions',\n",
       " 'FindInitializationErrors',\n",
       " 'FromString',\n",
       " 'HasExtension',\n",
       " 'HasField',\n",
       " 'IsInitialized',\n",
       " 'ListFields',\n",
       " 'MergeFrom',\n",
       " 'MergeFromString',\n",
       " 'ParseFromString',\n",
       " 'RegisterExtension',\n",
       " 'SerializePartialToString',\n",
       " 'SerializeToString',\n",
       " 'SetInParent',\n",
       " 'UnknownFields',\n",
       " 'WhichOneof',\n",
       " '_CheckCalledFromGeneratedFile',\n",
       " '_SetListener',\n",
       " '__class__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_extensions_by_name',\n",
       " '_extensions_by_number',\n",
       " 'doc_string',\n",
       " 'initializer',\n",
       " 'input',\n",
       " 'name',\n",
       " 'node',\n",
       " 'output',\n",
       " 'quantization_annotation',\n",
       " 'sparse_initializer',\n",
       " 'value_info']"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[input: \"161\"\n",
       "input: \"output\"\n",
       "output: \"12\"\n",
       "name: \"Concat_0\"\n",
       "op_type: \"Concat\"\n",
       "attribute {\n",
       "  name: \"axis\"\n",
       "  i: 2\n",
       "  type: INT\n",
       "}\n",
       ", input: \"12\"\n",
       "input: \"162\"\n",
       "output: \"14\"\n",
       "name: \"Expand_1\"\n",
       "op_type: \"Expand\"\n",
       ", output: \"19\"\n",
       "name: \"Constant_2\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"20\"\n",
       "name: \"Constant_3\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"19\"\n",
       "input: \"165\"\n",
       "input: \"20\"\n",
       "output: \"21\"\n",
       "name: \"Range_4\"\n",
       "op_type: \"Range\"\n",
       ", output: \"26\"\n",
       "name: \"Constant_5\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"27\"\n",
       "name: \"Constant_6\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"26\"\n",
       "input: \"168\"\n",
       "input: \"27\"\n",
       "output: \"28\"\n",
       "name: \"Range_7\"\n",
       "op_type: \"Range\"\n",
       ", output: \"33\"\n",
       "name: \"Constant_8\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"34\"\n",
       "name: \"Constant_9\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"33\"\n",
       "input: \"171\"\n",
       "input: \"34\"\n",
       "output: \"35\"\n",
       "name: \"Range_10\"\n",
       "op_type: \"Range\"\n",
       ", output: \"36\"\n",
       "name: \"Constant_11\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 3\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\\001\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"21\"\n",
       "input: \"36\"\n",
       "output: \"37\"\n",
       "name: \"Reshape_12\"\n",
       "op_type: \"Reshape\"\n",
       ", output: \"38\"\n",
       "name: \"Constant_13\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 2\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"28\"\n",
       "input: \"38\"\n",
       "output: \"39\"\n",
       "name: \"Reshape_14\"\n",
       "op_type: \"Reshape\"\n",
       ", output: \"40\"\n",
       "name: \"Constant_15\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"35\"\n",
       "input: \"40\"\n",
       "output: \"41\"\n",
       "name: \"Reshape_16\"\n",
       "op_type: \"Reshape\"\n",
       ", input: \"37\"\n",
       "input: \"39\"\n",
       "output: \"42\"\n",
       "name: \"Add_17\"\n",
       "op_type: \"Add\"\n",
       ", input: \"42\"\n",
       "input: \"41\"\n",
       "output: \"43\"\n",
       "name: \"Add_18\"\n",
       "op_type: \"Add\"\n",
       ", input: \"43\"\n",
       "output: \"44\"\n",
       "name: \"Shape_19\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"44\"\n",
       "output: \"45\"\n",
       "name: \"Shape_20\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"45\"\n",
       "output: \"46\"\n",
       "name: \"ConstantOfShape_21\"\n",
       "op_type: \"ConstantOfShape\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"47\"\n",
       "name: \"Constant_22\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"46\"\n",
       "input: \"47\"\n",
       "output: \"48\"\n",
       "name: \"Mul_23\"\n",
       "op_type: \"Mul\"\n",
       ", input: \"44\"\n",
       "input: \"48\"\n",
       "output: \"49\"\n",
       "name: \"Equal_24\"\n",
       "op_type: \"Equal\"\n",
       ", input: \"49\"\n",
       "output: \"50\"\n",
       "name: \"Cast_25\"\n",
       "op_type: \"Cast\"\n",
       "attribute {\n",
       "  name: \"to\"\n",
       "  i: 9\n",
       "  type: INT\n",
       "}\n",
       ", input: \"50\"\n",
       "input: \"46\"\n",
       "input: \"44\"\n",
       "output: \"51\"\n",
       "name: \"Where_26\"\n",
       "op_type: \"Where\"\n",
       ", input: \"37\"\n",
       "input: \"51\"\n",
       "output: \"52\"\n",
       "name: \"Expand_27\"\n",
       "op_type: \"Expand\"\n",
       ", input: \"52\"\n",
       "output: \"53\"\n",
       "name: \"Unsqueeze_28\"\n",
       "op_type: \"Unsqueeze\"\n",
       "attribute {\n",
       "  name: \"axes\"\n",
       "  ints: -1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"44\"\n",
       "output: \"54\"\n",
       "name: \"Shape_29\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"54\"\n",
       "output: \"55\"\n",
       "name: \"ConstantOfShape_30\"\n",
       "op_type: \"ConstantOfShape\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"56\"\n",
       "name: \"Constant_31\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"55\"\n",
       "input: \"56\"\n",
       "output: \"57\"\n",
       "name: \"Mul_32\"\n",
       "op_type: \"Mul\"\n",
       ", input: \"44\"\n",
       "input: \"57\"\n",
       "output: \"58\"\n",
       "name: \"Equal_33\"\n",
       "op_type: \"Equal\"\n",
       ", input: \"58\"\n",
       "output: \"59\"\n",
       "name: \"Cast_34\"\n",
       "op_type: \"Cast\"\n",
       "attribute {\n",
       "  name: \"to\"\n",
       "  i: 9\n",
       "  type: INT\n",
       "}\n",
       ", input: \"59\"\n",
       "input: \"55\"\n",
       "input: \"44\"\n",
       "output: \"60\"\n",
       "name: \"Where_35\"\n",
       "op_type: \"Where\"\n",
       ", input: \"39\"\n",
       "input: \"60\"\n",
       "output: \"61\"\n",
       "name: \"Expand_36\"\n",
       "op_type: \"Expand\"\n",
       ", input: \"61\"\n",
       "output: \"62\"\n",
       "name: \"Unsqueeze_37\"\n",
       "op_type: \"Unsqueeze\"\n",
       "attribute {\n",
       "  name: \"axes\"\n",
       "  ints: -1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"44\"\n",
       "output: \"63\"\n",
       "name: \"Shape_38\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"63\"\n",
       "output: \"64\"\n",
       "name: \"ConstantOfShape_39\"\n",
       "op_type: \"ConstantOfShape\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"65\"\n",
       "name: \"Constant_40\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"64\"\n",
       "input: \"65\"\n",
       "output: \"66\"\n",
       "name: \"Mul_41\"\n",
       "op_type: \"Mul\"\n",
       ", input: \"44\"\n",
       "input: \"66\"\n",
       "output: \"67\"\n",
       "name: \"Equal_42\"\n",
       "op_type: \"Equal\"\n",
       ", input: \"67\"\n",
       "output: \"68\"\n",
       "name: \"Cast_43\"\n",
       "op_type: \"Cast\"\n",
       "attribute {\n",
       "  name: \"to\"\n",
       "  i: 9\n",
       "  type: INT\n",
       "}\n",
       ", input: \"68\"\n",
       "input: \"64\"\n",
       "input: \"44\"\n",
       "output: \"69\"\n",
       "name: \"Where_44\"\n",
       "op_type: \"Where\"\n",
       ", input: \"41\"\n",
       "input: \"69\"\n",
       "output: \"70\"\n",
       "name: \"Expand_45\"\n",
       "op_type: \"Expand\"\n",
       ", input: \"70\"\n",
       "output: \"71\"\n",
       "name: \"Unsqueeze_46\"\n",
       "op_type: \"Unsqueeze\"\n",
       "attribute {\n",
       "  name: \"axes\"\n",
       "  ints: -1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"53\"\n",
       "input: \"62\"\n",
       "input: \"71\"\n",
       "output: \"72\"\n",
       "name: \"Concat_47\"\n",
       "op_type: \"Concat\"\n",
       "attribute {\n",
       "  name: \"axis\"\n",
       "  i: -1\n",
       "  type: INT\n",
       "}\n",
       ", input: \"44\"\n",
       "input: \"173\"\n",
       "output: \"78\"\n",
       "name: \"Concat_48\"\n",
       "op_type: \"Concat\"\n",
       "attribute {\n",
       "  name: \"axis\"\n",
       "  i: 0\n",
       "  type: INT\n",
       "}\n",
       ", input: \"14\"\n",
       "input: \"78\"\n",
       "output: \"79\"\n",
       "name: \"Reshape_49\"\n",
       "op_type: \"Reshape\"\n",
       ", input: \"2\"\n",
       "input: \"72\"\n",
       "input: \"79\"\n",
       "output: \"80\"\n",
       "name: \"ScatterND_50\"\n",
       "op_type: \"ScatterND\"\n",
       ", input: \"80\"\n",
       "input: \"6\"\n",
       "input: \"5\"\n",
       "output: \"81\"\n",
       "name: \"Conv_51\"\n",
       "op_type: \"Conv\"\n",
       "attribute {\n",
       "  name: \"dilations\"\n",
       "  ints: 1\n",
       "  type: INTS\n",
       "}\n",
       "attribute {\n",
       "  name: \"group\"\n",
       "  i: 1\n",
       "  type: INT\n",
       "}\n",
       "attribute {\n",
       "  name: \"kernel_shape\"\n",
       "  ints: 7\n",
       "  type: INTS\n",
       "}\n",
       "attribute {\n",
       "  name: \"pads\"\n",
       "  ints: 0\n",
       "  ints: 0\n",
       "  type: INTS\n",
       "}\n",
       "attribute {\n",
       "  name: \"strides\"\n",
       "  ints: 1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"81\"\n",
       "output: \"82\"\n",
       "name: \"Relu_52\"\n",
       "op_type: \"Relu\"\n",
       ", input: \"174\"\n",
       "input: \"82\"\n",
       "output: \"88\"\n",
       "name: \"Concat_53\"\n",
       "op_type: \"Concat\"\n",
       "attribute {\n",
       "  name: \"axis\"\n",
       "  i: 2\n",
       "  type: INT\n",
       "}\n",
       ", input: \"88\"\n",
       "input: \"175\"\n",
       "output: \"90\"\n",
       "name: \"Expand_54\"\n",
       "op_type: \"Expand\"\n",
       ", output: \"95\"\n",
       "name: \"Constant_55\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"96\"\n",
       "name: \"Constant_56\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"95\"\n",
       "input: \"178\"\n",
       "input: \"96\"\n",
       "output: \"97\"\n",
       "name: \"Range_57\"\n",
       "op_type: \"Range\"\n",
       ", output: \"102\"\n",
       "name: \"Constant_58\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"103\"\n",
       "name: \"Constant_59\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"102\"\n",
       "input: \"181\"\n",
       "input: \"103\"\n",
       "output: \"104\"\n",
       "name: \"Range_60\"\n",
       "op_type: \"Range\"\n",
       ", output: \"109\"\n",
       "name: \"Constant_61\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"110\"\n",
       "name: \"Constant_62\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"109\"\n",
       "input: \"184\"\n",
       "input: \"110\"\n",
       "output: \"111\"\n",
       "name: \"Range_63\"\n",
       "op_type: \"Range\"\n",
       ", output: \"112\"\n",
       "name: \"Constant_64\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 3\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\\001\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"97\"\n",
       "input: \"112\"\n",
       "output: \"113\"\n",
       "name: \"Reshape_65\"\n",
       "op_type: \"Reshape\"\n",
       ", output: \"114\"\n",
       "name: \"Constant_66\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 2\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"104\"\n",
       "input: \"114\"\n",
       "output: \"115\"\n",
       "name: \"Reshape_67\"\n",
       "op_type: \"Reshape\"\n",
       ", output: \"116\"\n",
       "name: \"Constant_68\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"111\"\n",
       "input: \"116\"\n",
       "output: \"117\"\n",
       "name: \"Reshape_69\"\n",
       "op_type: \"Reshape\"\n",
       ", input: \"113\"\n",
       "input: \"115\"\n",
       "output: \"118\"\n",
       "name: \"Add_70\"\n",
       "op_type: \"Add\"\n",
       ", input: \"118\"\n",
       "input: \"117\"\n",
       "output: \"119\"\n",
       "name: \"Add_71\"\n",
       "op_type: \"Add\"\n",
       ", input: \"119\"\n",
       "output: \"120\"\n",
       "name: \"Shape_72\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"120\"\n",
       "output: \"121\"\n",
       "name: \"Shape_73\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"121\"\n",
       "output: \"122\"\n",
       "name: \"ConstantOfShape_74\"\n",
       "op_type: \"ConstantOfShape\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"123\"\n",
       "name: \"Constant_75\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"122\"\n",
       "input: \"123\"\n",
       "output: \"124\"\n",
       "name: \"Mul_76\"\n",
       "op_type: \"Mul\"\n",
       ", input: \"120\"\n",
       "input: \"124\"\n",
       "output: \"125\"\n",
       "name: \"Equal_77\"\n",
       "op_type: \"Equal\"\n",
       ", input: \"125\"\n",
       "output: \"126\"\n",
       "name: \"Cast_78\"\n",
       "op_type: \"Cast\"\n",
       "attribute {\n",
       "  name: \"to\"\n",
       "  i: 9\n",
       "  type: INT\n",
       "}\n",
       ", input: \"126\"\n",
       "input: \"122\"\n",
       "input: \"120\"\n",
       "output: \"127\"\n",
       "name: \"Where_79\"\n",
       "op_type: \"Where\"\n",
       ", input: \"113\"\n",
       "input: \"127\"\n",
       "output: \"128\"\n",
       "name: \"Expand_80\"\n",
       "op_type: \"Expand\"\n",
       ", input: \"128\"\n",
       "output: \"129\"\n",
       "name: \"Unsqueeze_81\"\n",
       "op_type: \"Unsqueeze\"\n",
       "attribute {\n",
       "  name: \"axes\"\n",
       "  ints: -1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"120\"\n",
       "output: \"130\"\n",
       "name: \"Shape_82\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"130\"\n",
       "output: \"131\"\n",
       "name: \"ConstantOfShape_83\"\n",
       "op_type: \"ConstantOfShape\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"132\"\n",
       "name: \"Constant_84\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"131\"\n",
       "input: \"132\"\n",
       "output: \"133\"\n",
       "name: \"Mul_85\"\n",
       "op_type: \"Mul\"\n",
       ", input: \"120\"\n",
       "input: \"133\"\n",
       "output: \"134\"\n",
       "name: \"Equal_86\"\n",
       "op_type: \"Equal\"\n",
       ", input: \"134\"\n",
       "output: \"135\"\n",
       "name: \"Cast_87\"\n",
       "op_type: \"Cast\"\n",
       "attribute {\n",
       "  name: \"to\"\n",
       "  i: 9\n",
       "  type: INT\n",
       "}\n",
       ", input: \"135\"\n",
       "input: \"131\"\n",
       "input: \"120\"\n",
       "output: \"136\"\n",
       "name: \"Where_88\"\n",
       "op_type: \"Where\"\n",
       ", input: \"115\"\n",
       "input: \"136\"\n",
       "output: \"137\"\n",
       "name: \"Expand_89\"\n",
       "op_type: \"Expand\"\n",
       ", input: \"137\"\n",
       "output: \"138\"\n",
       "name: \"Unsqueeze_90\"\n",
       "op_type: \"Unsqueeze\"\n",
       "attribute {\n",
       "  name: \"axes\"\n",
       "  ints: -1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"120\"\n",
       "output: \"139\"\n",
       "name: \"Shape_91\"\n",
       "op_type: \"Shape\"\n",
       ", input: \"139\"\n",
       "output: \"140\"\n",
       "name: \"ConstantOfShape_92\"\n",
       "op_type: \"ConstantOfShape\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    dims: 1\n",
       "    data_type: 7\n",
       "    raw_data: \"\\001\\000\\000\\000\\000\\000\\000\\000\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", output: \"141\"\n",
       "name: \"Constant_93\"\n",
       "op_type: \"Constant\"\n",
       "attribute {\n",
       "  name: \"value\"\n",
       "  t {\n",
       "    data_type: 7\n",
       "    raw_data: \"\\377\\377\\377\\377\\377\\377\\377\\377\"\n",
       "  }\n",
       "  type: TENSOR\n",
       "}\n",
       ", input: \"140\"\n",
       "input: \"141\"\n",
       "output: \"142\"\n",
       "name: \"Mul_94\"\n",
       "op_type: \"Mul\"\n",
       ", input: \"120\"\n",
       "input: \"142\"\n",
       "output: \"143\"\n",
       "name: \"Equal_95\"\n",
       "op_type: \"Equal\"\n",
       ", input: \"143\"\n",
       "output: \"144\"\n",
       "name: \"Cast_96\"\n",
       "op_type: \"Cast\"\n",
       "attribute {\n",
       "  name: \"to\"\n",
       "  i: 9\n",
       "  type: INT\n",
       "}\n",
       ", input: \"144\"\n",
       "input: \"140\"\n",
       "input: \"120\"\n",
       "output: \"145\"\n",
       "name: \"Where_97\"\n",
       "op_type: \"Where\"\n",
       ", input: \"117\"\n",
       "input: \"145\"\n",
       "output: \"146\"\n",
       "name: \"Expand_98\"\n",
       "op_type: \"Expand\"\n",
       ", input: \"146\"\n",
       "output: \"147\"\n",
       "name: \"Unsqueeze_99\"\n",
       "op_type: \"Unsqueeze\"\n",
       "attribute {\n",
       "  name: \"axes\"\n",
       "  ints: -1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"129\"\n",
       "input: \"138\"\n",
       "input: \"147\"\n",
       "output: \"148\"\n",
       "name: \"Concat_100\"\n",
       "op_type: \"Concat\"\n",
       "attribute {\n",
       "  name: \"axis\"\n",
       "  i: -1\n",
       "  type: INT\n",
       "}\n",
       ", input: \"120\"\n",
       "input: \"186\"\n",
       "output: \"154\"\n",
       "name: \"Concat_101\"\n",
       "op_type: \"Concat\"\n",
       "attribute {\n",
       "  name: \"axis\"\n",
       "  i: 0\n",
       "  type: INT\n",
       "}\n",
       ", input: \"90\"\n",
       "input: \"154\"\n",
       "output: \"155\"\n",
       "name: \"Reshape_102\"\n",
       "op_type: \"Reshape\"\n",
       ", input: \"1\"\n",
       "input: \"148\"\n",
       "input: \"155\"\n",
       "output: \"156\"\n",
       "name: \"ScatterND_103\"\n",
       "op_type: \"ScatterND\"\n",
       ", input: \"156\"\n",
       "input: \"4\"\n",
       "input: \"3\"\n",
       "output: \"157\"\n",
       "name: \"Conv_104\"\n",
       "op_type: \"Conv\"\n",
       "attribute {\n",
       "  name: \"dilations\"\n",
       "  ints: 1\n",
       "  type: INTS\n",
       "}\n",
       "attribute {\n",
       "  name: \"group\"\n",
       "  i: 1\n",
       "  type: INT\n",
       "}\n",
       "attribute {\n",
       "  name: \"kernel_shape\"\n",
       "  ints: 7\n",
       "  type: INTS\n",
       "}\n",
       "attribute {\n",
       "  name: \"pads\"\n",
       "  ints: 0\n",
       "  ints: 0\n",
       "  type: INTS\n",
       "}\n",
       "attribute {\n",
       "  name: \"strides\"\n",
       "  ints: 1\n",
       "  type: INTS\n",
       "}\n",
       ", input: \"157\"\n",
       "output: \"158\"\n",
       "name: \"Relu_105\"\n",
       "op_type: \"Relu\"\n",
       ", input: \"158\"\n",
       "input: \"output\"\n",
       "output: \"159\"\n",
       "name: \"Add_106\"\n",
       "op_type: \"Add\"\n",
       ", input: \"159\"\n",
       "output: \"160\"\n",
       "name: \"Relu_107\"\n",
       "op_type: \"Relu\"\n",
       "]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model.graph.node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
