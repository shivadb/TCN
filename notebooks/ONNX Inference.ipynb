{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import torch\n",
    "import torch.onnx\n",
    "import numpy as np\n",
    "\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, clip=-1, cuda=True, dropout=0.05, epochs=50, ksize=7, levels=6, log_interval=100, lr=0.002, modelname='aug_k7l6', nhid=25, optim='Adam', permute=False, savedir=PosixPath('models'), savemodel=True, seed=-1, seq_augment=True)\n",
      "TCN/mnist_pixel/models/aug_k7l6.pt\n",
      "757\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('./TCN/mnist_pixel/models')\n",
    "data_path = Path('./TCN/mnist_pixel/data/mnist')\n",
    "model_name = 'aug_k7l6'\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "n_classes = 10\n",
    "\n",
    "args = pickle.load(open(model_path / (model_name+'_args.pkl'), 'rb'))\n",
    "print(args)\n",
    "channel_sizes = [args.nhid] * args.levels\n",
    "\n",
    "print(model_path / (model_name+'.pt'))\n",
    "\n",
    "_, test_loader = data_generator(data_path, batch_size)\n",
    "model = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize, inference=True)\n",
    "model.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(model.receptive_field)\n",
    "\n",
    "script_model = torch.jit.script(model)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    script_model.cuda()\n",
    "\n",
    "\n",
    "# model.set_fast_inference(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data, test_target = next(iter(test_loader))\n",
    "test_data = test_data.view(test_data.size()[0], 1, -1).cuda()\n",
    "test_input = test_data[:,:,0].view(test_data.size()[0], test_data.size()[1], 1)\n",
    "# test_input = test_data\n",
    "test_input.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_out = script_model(test_input)\n",
    "test_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1bhavsa/.local/lib/python3.7/site-packages/torch/jit/_trace.py:966: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "With rtol=1e-05 and atol=1e-05, found 10 element(s) (out of 10) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.11611056327819824 (-3.5729598999023438 vs. -3.4568493366241455), which occurred at index (0, 7).\n",
      "  _module_class,\n"
     ]
    }
   ],
   "source": [
    "trace_model = torch.jit.trace(model, test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export onnx model\n",
    "\n",
    "torch.onnx.export(\n",
    "    trace_model,\n",
    "    test_input,\n",
    "    f'{model_path}/{model_name}.onnx',\n",
    "    export_params=True,\n",
    "#     do_constant_folding=True,\n",
    "    keep_initializers_as_inputs=True,\n",
    "    opset_version=11,\n",
    "    input_names = ['input'],\n",
    "    output_names = ['output'],\n",
    "#     dynamic_axes={\n",
    "#                  'input' : {0 : 'batch_size'}, \n",
    "#                  'output' : {0 : 'batch_size'}\n",
    "#                  }\n",
    "    example_outputs=test_out\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "from onnx import helper, shape_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(model_path / (model_name+'.onnx'))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "# onnx.helper.printable_graph(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_model = shape_inference.infer_shapes(onnx_model)\n",
    "onnx.checker.check_model(inferred_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Fail",
     "evalue": "[ONNXRuntimeError] : 1 : FAIL : Exception during loading: /onnxruntime_src/onnxruntime/core/graph/function.cc:391 onnxruntime::FunctionImpl::FunctionImpl(const onnxruntime::Graph&, const NodeIndex&, const onnx::FunctionProto&, const onnxruntime::logging::Logger&) status.IsOK() was false. Resolve subgraph failed:Node (0x564fe6fb07c0_2) Op (Loop) [TypeInferenceError] Graph attribute inferencing failed: Node:0x564fe6fb07c0_2 Output:cond [ShapeInferenceError] Mismatch between number of source and target dimensions. Source=1 Target=0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFail\u001b[0m                                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7f976520d777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0monnx_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.onnx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mort_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnxruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInferenceSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_or_bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/onnxruntime/capi/session.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, providers)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to load from type '{0}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_or_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFail\u001b[0m: [ONNXRuntimeError] : 1 : FAIL : Exception during loading: /onnxruntime_src/onnxruntime/core/graph/function.cc:391 onnxruntime::FunctionImpl::FunctionImpl(const onnxruntime::Graph&, const NodeIndex&, const onnx::FunctionProto&, const onnxruntime::logging::Logger&) status.IsOK() was false. Resolve subgraph failed:Node (0x564fe6fb07c0_2) Op (Loop) [TypeInferenceError] Graph attribute inferencing failed: Node:0x564fe6fb07c0_2 Output:cond [ShapeInferenceError] Mismatch between number of source and target dimensions. Source=1 Target=0\n"
     ]
    }
   ],
   "source": [
    "onnx_path = model_path / (model_name+'.onnx')\n",
    "ort_session = onnxruntime.InferenceSession(str(onnx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 9 / 10 (90%)\nMax absolute difference: 0.53876376\nMax relative difference: 0.26503953\n x: array([[-2.571531, -2.101018, -2.800727, -3.385211, -2.661237, -3.102572,\n        -2.47572 , -3.681555, -0.921515, -2.469629]], dtype=float32)\n y: array([[-2.032768, -2.222053, -2.835331, -3.388276, -2.601045, -2.940132,\n        -2.14889 , -3.810934, -1.097009, -2.680756]], dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7c4c570c305f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# compare ONNX Runtime and PyTorch results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_allclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mort_outs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exported model has been tested with ONNXRuntime, and the result looks good!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_allclose\u001b[0;34m(actual, desired, rtol, atol, equal_nan, err_msg, verbose)\u001b[0m\n\u001b[1;32m   1527\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Not equal to tolerance rtol={rtol:g}, atol={atol:g}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1528\u001b[0m     assert_array_compare(compare, actual, desired, err_msg=str(err_msg),\n\u001b[0;32m-> 1529\u001b[0;31m                          verbose=verbose, header=header, equal_nan=equal_nan)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/testing/_private/utils.py\u001b[0m in \u001b[0;36massert_array_compare\u001b[0;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001b[0m\n\u001b[1;32m    840\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                                 names=('x', 'y'), precision=precision)\n\u001b[0;32m--> 842\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nNot equal to tolerance rtol=0.001, atol=1e-05\n\nMismatched elements: 9 / 10 (90%)\nMax absolute difference: 0.53876376\nMax relative difference: 0.26503953\n x: array([[-2.571531, -2.101018, -2.800727, -3.385211, -2.661237, -3.102572,\n        -2.47572 , -3.681555, -0.921515, -2.469629]], dtype=float32)\n y: array([[-2.032768, -2.222053, -2.835331, -3.388276, -2.601045, -2.940132,\n        -2.14889 , -3.810934, -1.097009, -2.680756]], dtype=float32)"
     ]
    }
   ],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(test_input)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(test_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0328, -2.2221, -2.8353, -3.3883, -2.6010, -2.9401, -2.1489, -3.8109,\n",
      "         -1.0970, -2.6808]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
      "[[-2.010258  -2.2737985 -2.8612118 -3.4314961 -2.5628037 -2.965137\n",
      "  -2.1034932 -3.8295255 -1.1005102 -2.6809928]]\n"
     ]
    }
   ],
   "source": [
    "print(test_out)\n",
    "print(ort_outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003d39b3afde4ec1834d2deea026e987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77130cbdf2fa4758a023ce4a8ecdb252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='True Label: N/A'), Label(value='Predicted Label: N/A')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5717879a0c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m#         time.sleep(0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_samples = 0\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "\n",
    "im_queue = [0 for i in range(28*28)]\n",
    "curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28))\n",
    "_, encoded_image = cv2.imencode('.png', curr_im)\n",
    "im_bytes = encoded_image.tobytes()\n",
    "im_disp = widgets.Image(value=im_bytes, width=200, height=200)\n",
    "\n",
    "true_val = widgets.Label(value=f'True Label: N/A')\n",
    "pred_val = widgets.Label(value=f'Predicted Label: N/A')\n",
    "label_disp = widgets.VBox((true_val, pred_val))\n",
    "\n",
    "display.display(im_disp)\n",
    "display.display(label_disp)\n",
    "\n",
    "for data, target in test_loader:\n",
    "    im = data.squeeze().cpu().detach().numpy()\n",
    "    rows, cols = im.shape\n",
    "    im = (im - im.min())\n",
    "    im = (im/im.max() * 255).astype('uint8')\n",
    "    curr_im = np.ones(im.shape, dtype=np.uint8)*255\n",
    "    \n",
    "    true_val.value = f'True Label: {target.item()}'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        num_samples += 1\n",
    "        curr_row = i // cols\n",
    "        curr_col = i % cols\n",
    "        \n",
    "        im_queue.append(im[curr_row,curr_col])\n",
    "        im_queue = im_queue[1:]\n",
    "        \n",
    "        curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28))\n",
    "        _, encoded_image = cv2.imencode('.png', curr_im)\n",
    "        im_bytes = encoded_image.tobytes()\n",
    "        im_disp.value = im_bytes\n",
    "        \n",
    "#         inp = data[:,:,i].view(data.size()[0], data.size()[1], 1)\n",
    "#         ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(inp)}\n",
    "#         ort_outs = ort_session.run(None, ort_inputs)\n",
    "    \n",
    "        output = trace_model(data[:,:,i].view(data.size()[0], data.size()[1], 1))\n",
    "        pred_orig = output.max(1, keepdim=True)[1] #max returns values and indices\n",
    "        \n",
    "#         pred = ort_outs[0].argmax(axis=1)[0] #max returns values and indices\n",
    "        \n",
    "        if num_samples > 500:\n",
    "            pred_val.value = f'Predicted Label: {pred_orig.item()}'\n",
    "            \n",
    "#         print(ort_outs[0])\n",
    "#         print(output)\n",
    "#         time.sleep(0.5)\n",
    "        \n",
    "    time.sleep(2)\n",
    "    \n",
    "    \n",
    "    for i in np.zeros(np.random.randint(50, 200)):\n",
    "        im_queue.append(0)\n",
    "        im_queue = im_queue[1:]\n",
    "        curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28)) \n",
    "        _, encoded_image = cv2.imencode('.png', curr_im)\n",
    "        im_bytes = encoded_image.tobytes()\n",
    "        im_disp.value = im_bytes\n",
    "        true_val.value = f'True Label: N/A'\n",
    "        num_samples += 1\n",
    "        \n",
    "#         inp = torch.tensor([i], dtype=torch.float).cuda().view(1, 1, 1)\n",
    "#         ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(inp)}\n",
    "#         ort_outs = ort_session.run(None, ort_inputs)\n",
    "        \n",
    "# #         output = model(torch.tensor([i], dtype=torch.float).cuda().view(1, 1, 1))\n",
    "#         pred = ort_outs[0].argmax(axis=1)[0] #max returns values and indices\n",
    "#         if num_samples > model.receptive_field:\n",
    "#             pred_val.value = f'Predicted Label: {pred.item()}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
