{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d4f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2038bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('./TCN/mnist_pixel/models')\n",
    "data_path = Path('./TCN/mnist_pixel/data/mnist')\n",
    "model_name = 'aug_k7l6'\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "n_classes = 10\n",
    "\n",
    "_, test_loader = data_generator(data_path, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31badc89",
   "metadata": {},
   "source": [
    "# Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d40701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, clip=-1, cuda=True, dropout=0.05, epochs=50, ksize=7, levels=6, log_interval=100, lr=0.002, modelname='aug_k7l6', nhid=25, optim='Adam', permute=False, savedir=PosixPath('models'), savemodel=True, seed=-1, seq_augment=True)\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "args = pickle.load(open(model_path / (model_name+'_args.pkl'), 'rb'))\n",
    "print(args)\n",
    "channel_sizes = [args.nhid] * args.levels\n",
    "\n",
    "model = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize, trt=True)\n",
    "model.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41f924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 1.6473996091862113 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        output = model(data_queue)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "torch_runtime = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {torch_runtime} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429b93b",
   "metadata": {},
   "source": [
    "# ONNX GPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb8d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx import helper, shape_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9df12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Model\n",
    "onnx_model = onnx.load(model_path / (model_name+'.onnx'))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "inferred_model = shape_inference.infer_shapes(onnx_model)\n",
    "onnx.checker.check_model(inferred_model)\n",
    "\n",
    "# Load Session\n",
    "onnx_path = model_path / (model_name+'.onnx')\n",
    "ort_session = ort.InferenceSession(str(onnx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "424887a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 0.5486956056283444 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: data_queue.cpu().numpy()}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "        pred = ort_outs[0].argmax(axis=1)[0]\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "onnx_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {onnx_runtimes} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68075b82",
   "metadata": {},
   "source": [
    "# TensorRT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c5088be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch2trt-0.2.0-py3.8-linux-x86_64.egg/torch2trt/converters/dummy_converters.py:6: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return method[0] == '_' and method[1] is not '_'\n"
     ]
    }
   ],
   "source": [
    "from torch2trt import TRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29d63633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load(model_path / (model_name+'_trt.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a85e7de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 0.5026635466789713 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        output = model_trt(data_queue)\n",
    "        pred = output.max(2, keepdim=True)[1]\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "tensorrt_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {tensorrt_runtimes} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8b65147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Runtime is 3.002392569373095 times faster than PyTorch (gpu)\n",
      "TensorRT Runtime is 3.277340519459494 times faster than regular PyTorch\n"
     ]
    }
   ],
   "source": [
    "print(f'ONNX Runtime is {torch_runtime/onnx_runtimes} times faster than PyTorch (gpu)')\n",
    "print(f'TensorRT Runtime is {torch_runtime/tensorrt_runtimes} times faster than regular PyTorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a65c3e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'binding_is_input',\n",
       " 'create_execution_context',\n",
       " 'create_execution_context_without_device_memory',\n",
       " 'device_memory_size',\n",
       " 'get_binding_bytes_per_component',\n",
       " 'get_binding_components_per_element',\n",
       " 'get_binding_dtype',\n",
       " 'get_binding_format',\n",
       " 'get_binding_format_desc',\n",
       " 'get_binding_index',\n",
       " 'get_binding_name',\n",
       " 'get_binding_shape',\n",
       " 'get_binding_vectorized_dim',\n",
       " 'get_location',\n",
       " 'get_profile_shape',\n",
       " 'get_profile_shape_input',\n",
       " 'has_implicit_batch_dimension',\n",
       " 'is_execution_binding',\n",
       " 'is_shape_binding',\n",
       " 'max_batch_size',\n",
       " 'max_workspace_size',\n",
       " 'name',\n",
       " 'num_bindings',\n",
       " 'num_layers',\n",
       " 'num_optimization_profiles',\n",
       " 'refittable',\n",
       " 'serialize']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_engine = model_trt.engine\n",
    "dir(model_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0f5af69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_engine.get_binding_shape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc2c5b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_path / (model_name+'.engine'), 'wb') as f:\n",
    "    f.write(model_trt.engine.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34ab54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
