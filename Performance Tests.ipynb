{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d4f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from TCN.mnist_pixel.utils import data_generator, average_runtime\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx import helper, shape_inference\n",
    "\n",
    "from torch2trt import TRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2038bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('./TCN/mnist_pixel/models')\n",
    "trt_model_path = Path('./TCN/mnist_pixel/models_trt')\n",
    "data_path = Path('./TCN/mnist_pixel/data/mnist')\n",
    "model_name = 'aug_k7l6'\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "n_classes = 10\n",
    "\n",
    "_, test_loader = data_generator(data_path, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31badc89",
   "metadata": {},
   "source": [
    "# Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d40701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, clip=-1, cuda=True, dropout=0.05, epochs=50, ksize=7, levels=6, log_interval=100, lr=0.002, modelname='aug_k7l6', nhid=25, optim='Adam', permute=False, savedir=PosixPath('models'), savemodel=True, seed=-1, seq_augment=True)\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "args = pickle.load(open(model_path / (model_name+'_args.pkl'), 'rb'))\n",
    "print(args)\n",
    "channel_sizes = [args.nhid] * args.levels\n",
    "\n",
    "model = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize, trt=True, apply_max=True)\n",
    "model.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41f924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 0 samples\n",
      "Finished running 1000 samples\n",
      "Finished running 2000 samples\n",
      "Finished running 3000 samples\n",
      "Finished running 4000 samples\n",
      "Finished running 5000 samples\n",
      "Finished running 6000 samples\n",
      "Finished running 7000 samples\n",
      "Finished running 8000 samples\n",
      "Finished running 9000 samples\n",
      "average runtime: 2.247088265419006 ms\n"
     ]
    }
   ],
   "source": [
    "torch_runtime = average_runtime(model, num_samples=10000)\n",
    "print(f'average runtime: {torch_runtime} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429b93b",
   "metadata": {},
   "source": [
    "# ONNX GPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9df12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Model\n",
    "onnx_model = onnx.load(model_path / (model_name+'.onnx'))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "inferred_model = shape_inference.infer_shapes(onnx_model)\n",
    "onnx.checker.check_model(inferred_model)\n",
    "\n",
    "# Load Session\n",
    "onnx_path = model_path / (model_name+'.onnx')\n",
    "ort_session = ort.InferenceSession(str(onnx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424887a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 1.212620218189395 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: data_queue.cpu().numpy()}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "onnx_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {onnx_runtimes} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68075b82",
   "metadata": {},
   "source": [
    "# TensorRT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8505e902",
   "metadata": {},
   "source": [
    "## torch2trt using ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d63633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt_onnx = TRTModule()\n",
    "model_trt_onnx.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_onnx_amax.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a85e7de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 0 samples\n",
      "Finished running 1000 samples\n",
      "Finished running 2000 samples\n",
      "Finished running 3000 samples\n",
      "Finished running 4000 samples\n",
      "Finished running 5000 samples\n",
      "Finished running 6000 samples\n",
      "Finished running 7000 samples\n",
      "Finished running 8000 samples\n",
      "Finished running 9000 samples\n",
      "average runtime: 0.4672294855117798 ms\n"
     ]
    }
   ],
   "source": [
    "trt_onnx_runtime = average_runtime(model_trt_onnx, num_samples=10000)\n",
    "print(f'average runtime: {trt_onnx_runtime} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee3396",
   "metadata": {},
   "source": [
    "## torch2trt using converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502dfcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt_no_onnx = TRTModule()\n",
    "model_trt_no_onnx.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_amax.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea9d37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 0 samples\n",
      "Finished running 1000 samples\n",
      "Finished running 2000 samples\n",
      "Finished running 3000 samples\n",
      "Finished running 4000 samples\n",
      "Finished running 5000 samples\n",
      "Finished running 6000 samples\n",
      "Finished running 7000 samples\n",
      "Finished running 8000 samples\n",
      "Finished running 9000 samples\n",
      "average runtime: 0.48139767646789555 ms\n"
     ]
    }
   ],
   "source": [
    "trt_no_onnx_runtime = average_runtime(model_trt_no_onnx, num_samples=10000)\n",
    "print(f'average runtime: {trt_no_onnx_runtime} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee8ee5",
   "metadata": {},
   "source": [
    "## torch2trt with ONNX - FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b65147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt_onnx_fp16 = TRTModule()\n",
    "model_trt_onnx_fp16.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_onnx_amax_fp16.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a65c3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 0 samples\n",
      "Finished running 1000 samples\n",
      "Finished running 2000 samples\n",
      "Finished running 3000 samples\n",
      "Finished running 4000 samples\n",
      "Finished running 5000 samples\n",
      "Finished running 6000 samples\n",
      "Finished running 7000 samples\n",
      "Finished running 8000 samples\n",
      "Finished running 9000 samples\n",
      "average runtime: 0.5889959812164306 ms\n"
     ]
    }
   ],
   "source": [
    "trt_onnx_fp16_runtime = average_runtime(model_trt_onnx_fp16, num_samples=10000, fp16=True)\n",
    "print(f'average runtime: {trt_onnx_fp16_runtime} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4b231",
   "metadata": {},
   "source": [
    "## torch2trt with converters - FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc2c5b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt_no_onnx_fp16 = TRTModule()\n",
    "model_trt_no_onnx_fp16.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_amax_fp16.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49e57ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished running 0 samples\n",
      "Finished running 1000 samples\n",
      "Finished running 2000 samples\n",
      "Finished running 3000 samples\n",
      "Finished running 4000 samples\n",
      "Finished running 5000 samples\n",
      "Finished running 6000 samples\n",
      "Finished running 7000 samples\n",
      "Finished running 8000 samples\n",
      "Finished running 9000 samples\n",
      "average runtime: 0.47009398937225344 ms\n"
     ]
    }
   ],
   "source": [
    "trt_no_onnx_fp16_runtime = average_runtime(model_trt_no_onnx_fp16, num_samples=10000, fp16=True)\n",
    "print(f'average runtime: {trt_no_onnx_fp16_runtime} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04a71b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT (using onnx) Runtime is 4.409675921520733 times faster than regular PyTorch\n",
      "TensorRT (no onnx) Runtime is 3.4072912494022343 times faster than regular PyTorch\n",
      "TensorRT (using onnx) with fp16 mode is 0.9841077976509873 times faster than full precision\n",
      "TensorRT (no onnx) with fp16 mode is 1.267474802359857 times faster than full precision\n"
     ]
    }
   ],
   "source": [
    "print(f'TensorRT (using onnx) Runtime is {torch_runtime/trt_onnx_runtime} times faster than regular PyTorch')\n",
    "print(f'TensorRT (no onnx) Runtime is {torch_runtime/trt_no_onnx_runtime} times faster than regular PyTorch')\n",
    "\n",
    "print(f'TensorRT (using onnx) with fp16 mode is {trt_onnx_runtime/ trt_onnx_fp16_runtime} times faster than full precision')\n",
    "print(f'TensorRT (no onnx) with fp16 mode is {trt_no_onnx_runtime/ trt_no_onnx_fp16_runtime} times faster than full precision')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34ab54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
