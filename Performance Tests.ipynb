{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5593dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e1e0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('./TCN/mnist_pixel/models')\n",
    "data_path = Path('./TCN/mnist_pixel/data/mnist')\n",
    "model_name = 'aug_k7l6'\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a942a7",
   "metadata": {},
   "source": [
    "# Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e84a200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, clip=-1, cuda=True, dropout=0.05, epochs=50, ksize=7, levels=6, log_interval=100, lr=0.002, modelname='aug_k7l6', nhid=25, optim='Adam', permute=False, savedir=PosixPath('models'), savemodel=True, seed=-1, seq_augment=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "args = pickle.load(open(model_path / (model_name+'_args.pkl'), 'rb'))\n",
    "print(args)\n",
    "channel_sizes = [args.nhid] * args.levels\n",
    "\n",
    "_, test_loader = data_generator(data_path, batch_size)\n",
    "model = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize, trt=True)\n",
    "model.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8e3643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 2.2639483213424683 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        output = model(data_queue)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        runtimes.append(time.time() - start)\n",
    "        \n",
    "print(f'Average runtime per sample: {np.mean(runtimes)*1000} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a10e2d",
   "metadata": {},
   "source": [
    "# ONNX GPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c89a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx import helper, shape_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f20e0ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Model\n",
    "onnx_model = onnx.load(model_path / (model_name+'.onnx'))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "inferred_model = shape_inference.infer_shapes(onnx_model)\n",
    "onnx.checker.check_model(inferred_model)\n",
    "\n",
    "# Load Session\n",
    "onnx_path = model_path / (model_name+'.onnx')\n",
    "ort_session = ort.InferenceSession(str(onnx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5469445c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 0.4884302920224715 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: data_queue.cpu().numpy()}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "        pred = ort_outs[0].argmax(axis=1)[0]\n",
    "        runtimes.append(time.time() - start)\n",
    "        \n",
    "print(f'Average runtime per sample: {np.mean(runtimes)*1000} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a521f",
   "metadata": {},
   "source": [
    "# TensorRT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9355ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch2trt import TRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2b53d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load(model_path / (model_name+'_trt.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2544c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
