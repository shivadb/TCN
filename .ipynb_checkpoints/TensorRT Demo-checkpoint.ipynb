{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d382a504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch2trt-0.2.0-py3.8-linux-x86_64.egg/torch2trt/converters/dummy_converters.py:6: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  return method[0] == '_' and method[1] is not '_'\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from torch2trt import torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e69d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, clip=-1, cuda=True, dropout=0.05, epochs=50, ksize=7, levels=6, log_interval=100, lr=0.002, modelname='aug_k7l6', nhid=25, optim='Adam', permute=False, savedir=PosixPath('models'), savemodel=True, seed=-1, seq_augment=True)\n",
      "TCN/mnist_pixel/models/aug_k7l6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('./TCN/mnist_pixel/models')\n",
    "data_path = Path('./TCN/mnist_pixel/data/mnist')\n",
    "model_name = 'aug_k7l6'\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "n_classes = 10\n",
    "\n",
    "args = pickle.load(open(model_path / (model_name+'_args.pkl'), 'rb'))\n",
    "print(args)\n",
    "channel_sizes = [args.nhid] * args.levels\n",
    "\n",
    "print(model_path / (model_name+'.pt'))\n",
    "\n",
    "_, test_loader = data_generator(data_path, batch_size)\n",
    "model = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize, apply_max=True)\n",
    "model.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(model.receptive_field)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f6ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,28*28)).cuda()\n",
    "model(x)\n",
    "x_fp16 = x.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f477be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_traced = torch.jit.trace(model, x)\n",
    "# model_trt = torch2trt(model, [x],  strict_type_constraints=True, use_onnx=True)\n",
    "# torch.save(model_trt.state_dict(), model_path / (model_name+'_trt.pt'))\n",
    "\n",
    "model_trt = torch2trt(model.half(), [x_fp16], use_onnx=True, fp16=True)\n",
    "torch.save(model_trt.state_dict(), model_path / (model_name+'_trt_fp16.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "463c274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorrt as trt\n",
    "# from torch2trt import tensorrt_converter\n",
    "# from torch2trt.torch2trt import add_missing_trt_tensors\n",
    "\n",
    "# @tensorrt_converter(\"torch.Tensor.topk\")\n",
    "# @tensorrt_converter(\"torch.topk\")\n",
    "# def convert_topk(ctx):\n",
    "#     input_tensor = ctx.method_args[0]\n",
    "#     # The K in \"topk\"\n",
    "#     top_k = ctx.method_args[1]\n",
    "#     output_val = ctx.method_return[0]\n",
    "#     output_idx = ctx.method_return[1]\n",
    "\n",
    "#     # Handle optional axis argument\n",
    "#     has_axis = len(ctx.method_args) > 2\n",
    "#     if has_axis:\n",
    "#         axis = ctx.method_args[2]\n",
    "#     else:\n",
    "#         axis = 0\n",
    "\n",
    "#     # input_trt = broadcast_trt_tensors(ctx.network, [input_trt], len(output[0].shape) - 1)\n",
    "#     # input_layer = ctx.get\n",
    "#     layer = ctx.network.add_topk(input_tensor._trt, trt.TopKOperation.MAX, top_k, axis)\n",
    "   \n",
    "#     # Has two outputs: (Tensor, LongTensor). \n",
    "#     # LongTensor is the corresponding indices to the topk operation\n",
    "#     output_val._trt, output_idx._trt = layer.get_output(0), layer.get_output(1)\n",
    "\n",
    "\n",
    "import tensorrt as trt\n",
    "from torch2trt import tensorrt_converter\n",
    "from torch2trt.torch2trt import add_missing_trt_tensors\n",
    "\n",
    "\n",
    "@tensorrt_converter('TCN.mnist_pixel.model.trt_argmax')\n",
    "def convert_argmax(ctx):\n",
    "    input_tensor = ctx.method_args[0]\n",
    "    # The K in \"topk\"\n",
    "    axis = ctx.method_kwargs['dim']\n",
    "    output = ctx.method_return\n",
    "    \n",
    "    if axis is None:\n",
    "        input_tensor = torch.flatten(input_tensor)\n",
    "        axis = 0\n",
    "    \n",
    "    input_tensor_trt = add_missing_trt_tensors(ctx.network, [input_tensor])[0]\n",
    "\n",
    "    layer = ctx.network.add_topk(input_tensor_trt, trt.TopKOperation.MAX, 1, axis)\n",
    "    \n",
    "    # layer.get_output(0) would give the max value\n",
    "    output._trt = layer.get_output(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bcd319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize, trt=True, apply_max=True)\n",
    "model2.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model2.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model2.cuda()\n",
    "\n",
    "model_trt_no_onnx = torch2trt(model2, [x], fp16=True)\n",
    "torch.save(model_trt_no_onnx.state_dict(), model_path / (model_name+'_trt_no_onnx_fp16.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b28e9b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cc891d08708e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_trt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTRTModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_trt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_trt.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "\n",
    "model_trt.load_state_dict(torch.load(model_path / (model_name+'_trt.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf0fd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81ccc0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31d0ce68a9614a8086636eda7bc3d6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60dc4c7448e0466e85756067ce6665a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='True Label: N/A'), Label(value='Predicted Label: N/A')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2212a7a6496e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mpred_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Predicted Label: {pred.item()}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_samples = 0\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "\n",
    "im_queue = [0 for i in range(28*28)]\n",
    "data_queue = torch.zeros((1,1,28*28)).cuda()\n",
    "curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28))\n",
    "_, encoded_image = cv2.imencode('.png', curr_im)\n",
    "im_bytes = encoded_image.tobytes()\n",
    "im_disp = widgets.Image(value=im_bytes, width=200, height=200)\n",
    "\n",
    "true_val = widgets.Label(value=f'True Label: N/A')\n",
    "pred_val = widgets.Label(value=f'Predicted Label: N/A')\n",
    "label_disp = widgets.VBox((true_val, pred_val))\n",
    "\n",
    "display.display(im_disp)\n",
    "display.display(label_disp)\n",
    "\n",
    "for data, target in test_loader:\n",
    "    im = data.squeeze().cpu().detach().numpy()\n",
    "    rows, cols = im.shape\n",
    "    im = (im - im.min())\n",
    "    im = (im/im.max() * 255).astype('uint8')\n",
    "    curr_im = np.ones(im.shape, dtype=np.uint8)*255\n",
    "    \n",
    "    true_val.value = f'True Label: {target.item()}'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        num_samples += 1\n",
    "        curr_row = i // cols\n",
    "        curr_col = i % cols\n",
    "        \n",
    "        im_queue.append(im[curr_row,curr_col])\n",
    "        im_queue = im_queue[1:]\n",
    "        \n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28))\n",
    "        _, encoded_image = cv2.imencode('.png', curr_im)\n",
    "        im_bytes = encoded_image.tobytes()\n",
    "        im_disp.value = im_bytes\n",
    "        \n",
    "        # output = model(data[:,:,i].view(data.size()[0], data.size()[1], 1))\n",
    "        output = model_trt(data_queue.half())\n",
    "        # pred = output.max(2, keepdim=True)[1] #max returns values and indices\n",
    "        pred = output\n",
    "        \n",
    "        if num_samples > model.receptive_field:\n",
    "            pred_val.value = f'Predicted Label: {pred.item()}'\n",
    "    \n",
    "        time.sleep(0.001)\n",
    "    \n",
    "    \n",
    "    for i in np.zeros(np.random.randint(50, 200)):\n",
    "        im_queue.append(0)\n",
    "        im_queue = im_queue[1:]\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = i\n",
    "        curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28)) \n",
    "        _, encoded_image = cv2.imencode('.png', curr_im)\n",
    "        im_bytes = encoded_image.tobytes()\n",
    "        im_disp.value = im_bytes\n",
    "        true_val.value = f'True Label: N/A'\n",
    "        num_samples += 1\n",
    "        # output = model(torch.tensor([i], dtype=torch.float).cuda().view(1, 1, 1))\n",
    "        output = model_trt(data_queue.half())\n",
    "        # pred = output.max(2, keepdim=True)[1] #max returns values and indices\n",
    "        pred = output\n",
    "        if num_samples > model.receptive_field:\n",
    "            pred_val.value = f'Predicted Label: {pred.item()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69735b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -0.1782, -12.2473,  -4.7862,  -8.8309,  -8.3275,  -8.6724,  -4.0078,\n",
       "          -10.8096,  -1.9996,  -7.1733]]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((1,1,784)).cuda()\n",
    "model_trt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8811af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TCN.tcn_trt import TCNTRTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74349c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [25] * 8\n",
    "kernel_size = 7\n",
    "# test_model = TCNTRTNet(1, num_channels, kernel_size=kernel_size).eval().cuda()\n",
    "test_model = TCN(trt=True).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efbec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.0824, 0.1307, 0.1124, 0.1008, 0.0800, 0.1120, 0.0733, 0.1091,\n",
       "         0.1024]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1,1,28*28)).cuda()\n",
    "test_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b598d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_trt = torch2trt(test_model, [x],  strict_type_constraints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e140d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.0824, 0.1307, 0.1124, 0.1008, 0.0800, 0.1120, 0.0733, 0.1091,\n",
       "         0.1024]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_trt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86554dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
