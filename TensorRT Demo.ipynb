{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d382a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from IPython import display\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from torch2trt import torch2trt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e69d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, clip=-1, cuda=True, dropout=0.05, epochs=50, ksize=7, levels=6, log_interval=100, lr=0.002, modelname='aug_k7l6', nhid=25, optim='Adam', permute=False, savedir=PosixPath('models'), savemodel=True, seed=-1, seq_augment=True)\n",
      "TCN/mnist_pixel/models/aug_k7l6.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757\n"
     ]
    }
   ],
   "source": [
    "model_path = Path('./TCN/mnist_pixel/models')\n",
    "data_path = Path('./TCN/mnist_pixel/data/mnist')\n",
    "model_name = 'aug_k7l6'\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "n_classes = 10\n",
    "\n",
    "args = pickle.load(open(model_path / (model_name+'_args.pkl'), 'rb'))\n",
    "print(args)\n",
    "channel_sizes = [args.nhid] * args.levels\n",
    "\n",
    "print(model_path / (model_name+'.pt'))\n",
    "\n",
    "_, test_loader = data_generator(data_path, batch_size)\n",
    "model = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize)\n",
    "model.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model.eval()\n",
    "\n",
    "print(model.receptive_field)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f477be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1,1,28*28)).cuda()\n",
    "# model_traced = torch.jit.trace(model, x)\n",
    "model_trt = torch2trt(model, [x],  strict_type_constraints=True, use_onnx=True)\n",
    "torch.save(model_trt.state_dict(), model_path / (model_name+'_trt.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b28e9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "\n",
    "model_trt.load_state_dict(torch.load(model_path / (model_name+'_trt.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf0fd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -0.0894, -14.9259,  -7.5343, -11.6455,  -7.7970, -10.3567,  -4.9296,\n",
       "          -12.9928,  -2.5707,  -7.1449]]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_trt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ccc0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "874a13b010e24da28e6d84973d7e15bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\x1c\\x08\\x00\\x00\\x00\\x00Wf\\x80H\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cd53bfc9454cb89977e12fe51b1449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='True Label: N/A'), Label(value='Predicted Label: N/A')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ca44ca37e584>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mpred_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Predicted Label: {pred.item()}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_samples = 0\n",
    "# fig, ax = plt.subplots(1,1)\n",
    "\n",
    "im_queue = [0 for i in range(28*28)]\n",
    "data_queue = torch.zeros((1,1,28*28)).cuda()\n",
    "curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28))\n",
    "_, encoded_image = cv2.imencode('.png', curr_im)\n",
    "im_bytes = encoded_image.tobytes()\n",
    "im_disp = widgets.Image(value=im_bytes, width=200, height=200)\n",
    "\n",
    "true_val = widgets.Label(value=f'True Label: N/A')\n",
    "pred_val = widgets.Label(value=f'Predicted Label: N/A')\n",
    "label_disp = widgets.VBox((true_val, pred_val))\n",
    "\n",
    "display.display(im_disp)\n",
    "display.display(label_disp)\n",
    "\n",
    "for data, target in test_loader:\n",
    "    im = data.squeeze().cpu().detach().numpy()\n",
    "    rows, cols = im.shape\n",
    "    im = (im - im.min())\n",
    "    im = (im/im.max() * 255).astype('uint8')\n",
    "    curr_im = np.ones(im.shape, dtype=np.uint8)*255\n",
    "    \n",
    "    true_val.value = f'True Label: {target.item()}'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        num_samples += 1\n",
    "        curr_row = i // cols\n",
    "        curr_col = i % cols\n",
    "        \n",
    "        im_queue.append(im[curr_row,curr_col])\n",
    "        im_queue = im_queue[1:]\n",
    "        \n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28))\n",
    "        _, encoded_image = cv2.imencode('.png', curr_im)\n",
    "        im_bytes = encoded_image.tobytes()\n",
    "        im_disp.value = im_bytes\n",
    "        \n",
    "        # output = model(data[:,:,i].view(data.size()[0], data.size()[1], 1))\n",
    "        output = model_trt(data_queue)\n",
    "        pred = output.max(2, keepdim=True)[1] #max returns values and indices\n",
    "        \n",
    "        if num_samples > model.receptive_field:\n",
    "            pred_val.value = f'Predicted Label: {pred.item()}'\n",
    "    \n",
    "        time.sleep(0.001)\n",
    "    \n",
    "    \n",
    "    for i in np.zeros(np.random.randint(50, 200)):\n",
    "        im_queue.append(0)\n",
    "        im_queue = im_queue[1:]\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = i\n",
    "        curr_im = np.array(im_queue, dtype=np.uint8).reshape((28,28)) \n",
    "        _, encoded_image = cv2.imencode('.png', curr_im)\n",
    "        im_bytes = encoded_image.tobytes()\n",
    "        im_disp.value = im_bytes\n",
    "        true_val.value = f'True Label: N/A'\n",
    "        num_samples += 1\n",
    "        # output = model(torch.tensor([i], dtype=torch.float).cuda().view(1, 1, 1))\n",
    "        output = model_trt(data_queue)\n",
    "        pred = output.max(2, keepdim=True)[1] #max returns values and indices\n",
    "        if num_samples > model.receptive_field:\n",
    "            pred_val.value = f'Predicted Label: {pred.item()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c69735b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8811af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TCN.tcn_trt import TCNTRTNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74349c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [25] * 8\n",
    "kernel_size = 7\n",
    "# test_model = TCNTRTNet(1, num_channels, kernel_size=kernel_size).eval().cuda()\n",
    "test_model = TCN(trt=True).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efbec80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.0824, 0.1307, 0.1124, 0.1008, 0.0800, 0.1120, 0.0733, 0.1091,\n",
       "         0.1024]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1,1,28*28)).cuda()\n",
    "test_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b598d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_trt = torch2trt(test_model, [x],  strict_type_constraints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e140d210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0968, 0.0824, 0.1307, 0.1124, 0.1008, 0.0800, 0.1120, 0.0733, 0.1091,\n",
       "         0.1024]], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_trt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86554dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
