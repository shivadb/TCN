{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6d4f97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from TCN.mnist_pixel.utils import data_generator\n",
    "from TCN.mnist_pixel.model import TCN\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx import helper, shape_inference\n",
    "\n",
    "from torch2trt import TRTModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2038bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('./TCN/mnist_pixel/models')\n",
    "trt_model_path = Path('./TCN/mnist_pixel/models_trt')\n",
    "data_path = Path('./TCN/mnist_pixel/data/mnist')\n",
    "model_name = 'aug_k7l6'\n",
    "batch_size = 1\n",
    "in_channels = 1\n",
    "n_classes = 10\n",
    "\n",
    "_, test_loader = data_generator(data_path, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31badc89",
   "metadata": {},
   "source": [
    "# Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45d40701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=64, clip=-1, cuda=True, dropout=0.05, epochs=50, ksize=7, levels=6, log_interval=100, lr=0.002, modelname='aug_k7l6', nhid=25, optim='Adam', permute=False, savedir=PosixPath('models'), savemodel=True, seed=-1, seq_augment=True)\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "\n",
    "args = pickle.load(open(model_path / (model_name+'_args.pkl'), 'rb'))\n",
    "print(args)\n",
    "channel_sizes = [args.nhid] * args.levels\n",
    "\n",
    "model = TCN(in_channels, n_classes, channel_sizes, kernel_size=args.ksize, trt=True)\n",
    "model.load_state_dict(torch.load(model_path / (model_name+'.pt')), strict=False)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41f924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 3.1882090227944513 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        output = model(data_queue)\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "torch_runtime = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {torch_runtime} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429b93b",
   "metadata": {},
   "source": [
    "# ONNX GPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9df12bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Model\n",
    "onnx_model = onnx.load(model_path / (model_name+'.onnx'))\n",
    "onnx.checker.check_model(onnx_model)\n",
    "inferred_model = shape_inference.infer_shapes(onnx_model)\n",
    "onnx.checker.check_model(inferred_model)\n",
    "\n",
    "# Load Session\n",
    "onnx_path = model_path / (model_name+'.onnx')\n",
    "ort_session = ort.InferenceSession(str(onnx_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424887a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 1.1331963295839271 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: data_queue.cpu().numpy()}\n",
    "        ort_outs = ort_session.run(None, ort_inputs)\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "onnx_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {onnx_runtimes} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68075b82",
   "metadata": {},
   "source": [
    "# TensorRT Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8505e902",
   "metadata": {},
   "source": [
    "## torch2trt using ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29d63633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_onnx_amax.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a85e7de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 0.8545281631605965 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        output = model_trt(data_queue)\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "tensorrt_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {tensorrt_runtimes} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ee3396",
   "metadata": {},
   "source": [
    "## torch2trt using converters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "502dfcbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt_no_onnx = TRTModule()\n",
    "model_trt_no_onnx.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_amax.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea9d37be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 0.9404097892800156 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        output = model_trt_no_onnx(data_queue)\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "tensorrt_no_onnx_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {tensorrt_no_onnx_runtimes} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee8ee5",
   "metadata": {},
   "source": [
    "## torch2trt with ONNX - FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b65147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt_fp16 = TRTModule()\n",
    "model_trt_fp16.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_onnx_amax_fp16.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a65c3e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 0.8252052020053474 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time()\n",
    "        output = model_trt_fp16(data_queue)\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "tensorrt_runtimes_fp16 = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {tensorrt_runtimes_fp16} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4b231",
   "metadata": {},
   "source": [
    "## torch2trt with converters - FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc2c5b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Model\n",
    "model_trt_no_onnx_fp16 = TRTModule()\n",
    "model_trt_no_onnx_fp16.load_state_dict(torch.load(trt_model_path / (model_name+'_trt_amax_fp16.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49e57ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Running sample image 10\n",
      "Average runtime per sample: 0.8086569759310509 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "runtimes = []\n",
    "\n",
    "data_queue = torch.zeros((1,1,28*28))\n",
    "data_queue = data_queue.cuda() if torch.cuda.is_available() else data_queue\n",
    "\n",
    "for s, (data, target) in enumerate(test_loader):\n",
    "    if s >= num_samples:\n",
    "        break\n",
    "    print(f'Running sample image {s+1}')\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "    \n",
    "    data = data.view(data.size()[0], 1, -1)\n",
    "    \n",
    "    for i in range(data.size()[2]):\n",
    "        data_queue = data_queue.roll(-1, 2)\n",
    "        data_queue[:,:,-1] = data[:,:,i]\n",
    "        \n",
    "        start = time.time() \n",
    "        output = model_trt_no_onnx_fp16(data_queue)\n",
    "        runtimes.append(time.time() - start)\n",
    "\n",
    "tensorrt_no_onnx_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {tensorrt_no_onnx_runtimes} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04a71b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sample image 0\n",
      "Running sample image 1\n",
      "Running sample image 2\n",
      "Running sample image 3\n",
      "Running sample image 4\n",
      "Running sample image 5\n",
      "Running sample image 6\n",
      "Running sample image 7\n",
      "Running sample image 8\n",
      "Running sample image 9\n",
      "Average runtime per sample: 0.8949189769978426 ms\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10*784\n",
    "runtimes = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    if i % 784 == 0: print(f'Running sample image {i//784}')\n",
    "    x = torch.rand((1,1,28*28)).cuda()\n",
    "    \n",
    "    start = time.time()\n",
    "    output = model_trt_no_onnx(x)\n",
    "    runtimes.append(time.time() - start)\n",
    "\n",
    "test_runtimes = np.mean(runtimes)*1000\n",
    "print(f'Average runtime per sample: {test_runtimes} ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a34ab54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'ONNX Runtime is {torch_runtime/onnx_runtimes} times faster than PyTorch (gpu)')\n",
    "print(f'TensorRT (using onnx) Runtime is {torch_runtime/tensorrt_runtimes} times faster than regular PyTorch')\n",
    "print(f'TensorRT (no onnx) Runtime is {torch_runtime/tensorrt_no_onnx_runtimes} times faster than regular PyTorch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
